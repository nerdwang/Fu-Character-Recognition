{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1153e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import pi as pi\n",
    "from numpy import exp as exp\n",
    "from numpy import cos as cos\n",
    "from numpy import sin as sin\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import hog\n",
    "from scipy.ndimage import sobel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b5f4b",
   "metadata": {},
   "source": [
    "# 弹性纵横网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06c765ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutline(image,sub1=None,sub2=None,sub3=None,sub4=None,mode='just cut',t=6):         #注意！image必须要是0-1反转过的0-1二值图片！\n",
    "    #statistics=[]\n",
    "    #image = pic.copy()\n",
    "    #img = binaryImage(image)\n",
    "    #plant = plant != 255\n",
    "    #plant = image.astype(int)\n",
    "    allPoint = np.sum(image)\n",
    "    if allPoint==0:\n",
    "        return np.zeros(t**2)\n",
    "    perline = allPoint / t\n",
    "    lie = np.sum(image,axis = 0)\n",
    "    hang = np.sum(image,axis = 1)\n",
    "    \n",
    "    for i in range(1,len(lie)):\n",
    "        lie[i] = lie[i-1] + lie[i]\n",
    "    for i in range(1,len(hang)):\n",
    "        hang[i] = hang[i-1] + hang[i]\n",
    "        \n",
    "    lieline = [0] * t + [image.shape[1]]\n",
    "    hangline = [0] * t + [image.shape[0]]\n",
    "   \n",
    "    for i in range(0,t-1):\n",
    "        lieline[i+1] = np.argmin(abs(lie - perline * (i + 1))) + 1\n",
    "        #print(np.argmin(abs(lie - perline * (i + 1))) + 1)\n",
    "        hangline[i+1] = np.argmin(abs(hang - perline * (i + 1))) + 1\n",
    "    \n",
    "    if mode=='just cut':\n",
    "        return lieline,hangline\n",
    "        \n",
    "    if mode=='statistics':\n",
    "        statistics=np.zeros(t**2)\n",
    "\n",
    "        for j in range(t):\n",
    "            for k in range(t):\n",
    "                region=image[hangline[j]:hangline[j+1],lieline[k]:lieline[k+1]]\n",
    "                statistics[j*t+k]=np.sum(region)/allPoint\n",
    "        return statistics\n",
    "    \n",
    "    if mode=='sub-statistics':\n",
    "        statistics=np.zeros(t**2*4)\n",
    "        for j in range(t):\n",
    "            for k in range(t):\n",
    "                region1=sub1[hangline[j]:hangline[j+1],lieline[k]:lieline[k+1]]\n",
    "                region2=sub2[hangline[j]:hangline[j+1],lieline[k]:lieline[k+1]]\n",
    "                region3=sub3[hangline[j]:hangline[j+1],lieline[k]:lieline[k+1]]\n",
    "                region4=sub4[hangline[j]:hangline[j+1],lieline[k]:lieline[k+1]]\n",
    "                \n",
    "                statistics[j*t+k]=np.sum(region1)/allPoint\n",
    "                statistics[t**2+j*t+k]=np.sum(region2)/allPoint\n",
    "                statistics[2*t**2+j*t+k]=np.sum(region2)/allPoint\n",
    "                statistics[3*t**2+j*t+k]=np.sum(region2)/allPoint\n",
    "                \n",
    "        return statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae06dd",
   "metadata": {},
   "source": [
    "# 子笔划提取-特征提取1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a221212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCountLength(img,mode01 = False):\n",
    "    img = img.astype(int)\n",
    "    arr = np.pad(img, pad_width=1, mode='constant', constant_values=0)\n",
    "    result = np.zeros((img.shape[0],img.shape[1],4))\n",
    "    \n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if img[i,j] == 0:\n",
    "                continue\n",
    "                \n",
    "            #设置横\n",
    "            if j == 0 or img[i,j-1] == 0:\n",
    "                result[i,j,0] = np.argmin(arr[i+1,j+1:])\n",
    "            else:\n",
    "                result[i,j,0] = result[i,j-1,0]\n",
    "            \n",
    "            #设置竖\n",
    "            if i == 0 or img[i-1,j] == 0:\n",
    "                result[i,j,2] = np.argmin(arr[i+1:,j+1])\n",
    "                \n",
    "            else:\n",
    "                result[i,j,2] = result[i-1,j,2]\n",
    "                \n",
    "                \n",
    "            #设置撇\n",
    "            if i == 0 or j == img.shape[1] - 1 or img[i-1,j+1] == 0:\n",
    "                result[i,j,1] = np.argmin(np.fliplr(arr[i+1:,:j+2]).diagonal())\n",
    "            else:\n",
    "                result[i,j,1] = result[i-1,j+1,1]\n",
    "                \n",
    "            #设置捺\n",
    "            if i == 0 or j == 0 or img[i-1,j-1] == 0:\n",
    "                result[i,j,3] = np.argmin(arr[i+1:,j+1:].diagonal())\n",
    "            else:\n",
    "                result[i,j,3] = result[i-1,j-1,3]\n",
    "    \n",
    "     \n",
    "    #加上上下两个\n",
    "    temp = result.copy()\n",
    "    result[1:,1:] += temp[:img.shape[0] - 1,:img.shape[1] - 1]\n",
    "    result[:img.shape[0] - 1,:img.shape[1] - 1] += temp[1:,1:]\n",
    "    result[1:,:img.shape[1] - 1] += temp[:img.shape[0] - 1,1:]\n",
    "    result[:img.shape[0] - 1,1:] += temp[1:,:img.shape[0] - 1]\n",
    "    \n",
    "    #return result\n",
    "    \n",
    "    #取最大值\n",
    "    temp = np.max(result,axis = 2)\n",
    "    r = np.zeros_like(result)\n",
    "    for i in range(4):\n",
    "        r[:,:,i] = np.equal(result[:,:,i], temp)\n",
    "\n",
    "    temp = np.equal(temp,0).astype(int)\n",
    "    for i in range(4):\n",
    "        r[:,:,i] -= temp\n",
    "\n",
    "    \n",
    "    #return r\n",
    "        \n",
    "        \n",
    "    #取前后\n",
    "    result = r.copy()\n",
    "    result[1:,:,0] += r[:img.shape[0]-1,:,0]\n",
    "    result[:img.shape[0]-1,:,0] += r[1:,:,0]\n",
    "    \n",
    "    result[1:,1:,1] += r[:img.shape[0] - 1,:img.shape[1] - 1,1]\n",
    "    result[:img.shape[0] - 1,:img.shape[1] - 1,1] += r[1:,1:,1]\n",
    "    \n",
    "    result[:,1:,2] += r[:,:img.shape[0]-1,2]\n",
    "    result[:,:img.shape[0]-1,2] += r[:,1:,2]\n",
    "    \n",
    "    result[1:,:img.shape[1] - 1,3] += r[:img.shape[0] - 1,1:,3]\n",
    "    result[:img.shape[0] - 1,1:,3] += r[1:,:img.shape[0] - 1,3]\n",
    "    \n",
    "    \n",
    "    #先加起来，只要大于零就代表有，因此取bool值再反转即可\n",
    "    result = result.astype(bool) == False\n",
    "    \n",
    "    if mode01:\n",
    "        return (result==0).astype(int)\n",
    "    \n",
    "    result = result.astype(np.uint8) * 255\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53d55701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics_strokes_extraction(img,t=6):\n",
    "    result = makeCountLength(img, mode01 = True)\n",
    "    heng,shu,pie,na = result[:,:,0],result[:,:,2],result[:,:,1],result[:,:,3]\n",
    "    strokes_stats = cutline(img,heng,shu,pie,na,'sub-statistics')\n",
    "    return strokes_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21443b26",
   "metadata": {},
   "source": [
    "# 内外轮廓+hog-特征提取2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4c9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(img):\n",
    "    h, w = img.shape\n",
    "\n",
    "    # 内外轮廓特征\n",
    "    feature1 = np.zeros(32)\n",
    "    # 上下\n",
    "    for cnt in range(4):\n",
    "        p1 = p2 = p3 = p4 = 0\n",
    "        for j in range(int(w / 4 * cnt), int(w / 4 * (cnt + 1))):\n",
    "            # 上\n",
    "            i = 0\n",
    "            while img[i, j] == 0 and i < h - 1:\n",
    "                p1 += 1\n",
    "                i += 1\n",
    "            while img[i, j] == 1 and i < h - 1:\n",
    "                i += 1\n",
    "            while img[i, j] == 0 and i < h - 1:\n",
    "                p2 += 1\n",
    "                i += 1\n",
    "            # 下\n",
    "            i = h - 1\n",
    "            while img[i, j] == 0 and i > 0:\n",
    "                p3 += 1\n",
    "                i -= 1\n",
    "            while img[i, j] == 1 and i > 0:\n",
    "                i -= 1\n",
    "            while img[i, j] == 0 and i > 0:\n",
    "                p4 += 1\n",
    "                i -= 1\n",
    "        feature1[cnt] = p1\n",
    "        feature1[cnt + 16] = p2\n",
    "        feature1[cnt + 4] = p3\n",
    "        feature1[cnt + 20] = p4\n",
    "\n",
    "    # 左右\n",
    "    for cnt in range(8, 12):\n",
    "        p1 = p2 = p3 = p4 = 0\n",
    "        for i in range(int(h / 4 * (cnt - 8)), int(h / 4 * (cnt - 7))):\n",
    "            # 左\n",
    "            j = 0\n",
    "            while img[i, j] == 0 and j < w - 1:\n",
    "                p1 += 1\n",
    "                j += 1\n",
    "            while img[i, j] == 1 and j < w - 1:\n",
    "                j += 1\n",
    "            while img[i, j] == 0 and j < w - 1:\n",
    "                p2 += 1\n",
    "                j += 1\n",
    "            # 右\n",
    "            j = w - 1\n",
    "            while img[i, j] == 0 and j > 0:\n",
    "                p3 += 1\n",
    "                j -= 1\n",
    "            while img[i, j] == 1 and j > 0:\n",
    "                j -= 1\n",
    "            while img[i, j] == 0 and j > 0:\n",
    "                p4 += 1\n",
    "                j -= 1\n",
    "        feature1[cnt] = p1\n",
    "        feature1[cnt + 16] = p2\n",
    "        feature1[cnt + 4] = p3\n",
    "        feature1[cnt + 20] = p4\n",
    "\n",
    "    # HoG特征\n",
    "    feature2 = hog(img, pixels_per_cell=(160,160), cells_per_block=(2, 2), orientations=9)\n",
    "    feature2 = feature2.flatten()\n",
    "    combined_feature = np.concatenate([feature1, feature2])\n",
    "\n",
    "    return combined_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4594a032",
   "metadata": {},
   "source": [
    "# gabor-特征提取3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b72f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fixed_size_gabor_filters(ksize, thetas, lambd, sigma, gamma, psi):\n",
    "    filters = []\n",
    "    for theta in thetas:\n",
    "        kern = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_32F)\n",
    "        filters.append(kern)\n",
    "    return filters\n",
    "\n",
    "def gabor_extraction(image, filters, t=5):\n",
    "    hang, lie = cutline(image, t=t)\n",
    "    feature = np.zeros(t * t * len(filters))\n",
    "\n",
    "    for i in range(t):\n",
    "        for j in range(t):\n",
    "            region = image[hang[i]:hang[i+1], lie[j]:lie[j+1]]\n",
    "            if region.shape[0] == 0 or region.shape[1] == 0:\n",
    "                continue\n",
    "            region = region.astype('float32')\n",
    "            for k, kern in enumerate(filters):\n",
    "                fimg = cv2.filter2D(region, cv2.CV_8UC3, kern)\n",
    "                feature_idx = i * t * len(filters) + j * len(filters) + k\n",
    "                feature[feature_idx] = np.sum(fimg)\n",
    "\n",
    "    return feature\n",
    "\n",
    "# 创建固定大小的Gabor滤波器\n",
    "ksize = 21 # 你可以根据需要调整这个大小\n",
    "thetas = np.arange(0, np.pi, np.pi / 4)\n",
    "lambd = 10.0\n",
    "sigma = 5.0\n",
    "gamma = 0.5\n",
    "psi = 0\n",
    "filters = build_fixed_size_gabor_filters(ksize, thetas, lambd, sigma, gamma, psi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792a1007",
   "metadata": {},
   "source": [
    "# gabor双弹性网络-特征提取4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0471dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fixed_size_gabor_filters(ksize, thetas, lambd, sigma, gamma, psi):\n",
    "    filters = []\n",
    "    for theta in thetas:\n",
    "        kern = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_32F)\n",
    "        filters.append(kern)\n",
    "    return filters\n",
    "\n",
    "def gabor_extraction(image, filters, t=5):\n",
    "    hang, lie = cutline(image, t=t, mode='just cut')\n",
    "    feature = np.zeros(t * t * len(filters))\n",
    "\n",
    "    for i in range(t):\n",
    "        for j in range(t):\n",
    "            region = image[hang[i]:hang[i+1], lie[j]:lie[j+1]]\n",
    "            if region.shape[0] == 0 or region.shape[1] == 0:\n",
    "                continue\n",
    "            region = region.astype('float32')\n",
    "            for k, kern in enumerate(filters):\n",
    "                fimg = cv2.filter2D(region, cv2.CV_8UC3, kern)\n",
    "                feature_idx = i * t * len(filters) + j * len(filters) + k\n",
    "                feature[feature_idx] = np.sum(fimg)\n",
    "\n",
    "    return feature\n",
    "\n",
    "# 创建固定大小的Gabor滤波器\n",
    "ksize = 21 # 你可以根据需要调整这个大小\n",
    "thetas = np.arange(0, np.pi, np.pi / 4)\n",
    "lambd = 10.0\n",
    "sigma = 5.0\n",
    "gamma = 0.5\n",
    "psi = 0\n",
    "filters = build_fixed_size_gabor_filters(ksize, thetas, lambd, sigma, gamma, psi)\n",
    "\n",
    "def turn45(img):\n",
    "    # 获取图像中心坐标\n",
    "    center = (img.shape[1] // 2, img.shape[0] // 2)\n",
    "    \n",
    "    # 设置旋转矩阵\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, 45, 1.0)\n",
    "    \n",
    "    # 旋转图像\n",
    "    rotated_image = cv2.warpAffine(img, rotation_matrix, (img.shape[1], img.shape[0]), borderValue=(255,))\n",
    "\n",
    "    return rotated_image\n",
    "\n",
    "\n",
    "def gabor_ZiBiHua(img):\n",
    "    image = (img == False).astype(np.uint8) * 255\n",
    "\n",
    "    ZBH = makeCountLength(image)\n",
    "    feature = np.array([])\n",
    "    for i in range(4):\n",
    "        if i % 2 == 0:\n",
    "            pic = (ZBH[:,:,i] == 0).astype(int)\n",
    "            feature = np.append(feature,gabor_extraction(pic,filters,t = 5))\n",
    "        else:\n",
    "            pic = (turn45(ZBH[:,:,i]) == 0).astype(int)\n",
    "            feature = np.append(feature,gabor_extraction(pic,filters,t = 3))\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989e257",
   "metadata": {},
   "source": [
    "# hough特征-特征提取5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8daeacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.linspace(-np.pi/2, np.pi/2, 128)\n",
    "coses= np.cos(thetas)\n",
    "sins=np.sin(thetas)\n",
    "theta_intervals=np.array([0, 18,36,54,73,91,109,128])      #将hough累计器从(140,128)降维到(16,7)时，对theta轴的划分\n",
    "\n",
    "def hough_extraction(image,N=8):\n",
    "    # 计算重心\n",
    "    rows, cols = np.where(image == 1)  # 找到所有黑色像素的位置\n",
    "    centroid = (round(np.mean(rows)),round(np.mean(cols)))\n",
    "    # 计算所有黑色像素点到重心的距离\n",
    "    distances = np.sqrt((cols - centroid[1])**2 + (rows - centroid[0])**2)\n",
    "    # 找到最大距离\n",
    "    max_distance = np.max(distances)\n",
    "    max_radius = int(np.floor(max_distance)+1)\n",
    "    black_pixel_counts = np.zeros(max_radius)\n",
    "    for radius in range(1, max_radius + 1):\n",
    "        # 计算当前半径内的黑色像素数量\n",
    "        count = np.sum(np.sqrt((cols - centroid[0])**2 + (rows - centroid[1])**2) <= radius )\n",
    "        black_pixel_counts[radius-1]=count\n",
    "    total=np.sum(image)\n",
    "    perline = total / N  \n",
    "    ideal_radii=np.zeros(2*N+1)\n",
    "    ideal_radii[0]=-max_radius\n",
    "    ideal_radii[2*N]=max_radius\n",
    "    # 循环以找到N-1个合适的弹性分割半径\n",
    "    for i in range(N-1):\n",
    "        # 找到最接近目标差异数累积的半径\n",
    "        ideal_radii[N+i+1]= np.argmin(abs(black_pixel_counts - perline * (i + 1))) + 1 \n",
    "        ideal_radii[N-i-1]= -ideal_radii[N+i+1]\n",
    "    \n",
    "    \n",
    "    radius= np.linspace(-max_radius,max_radius,140)\n",
    "    bins = np.digitize(radius, ideal_radii,right=True)  #将radius划分到弹性网络的各圈内\n",
    "    rows, cols=rows-centroid[0], cols-centroid[1]    #减去重心归一化\n",
    "    accumulator = np.zeros((140, 128))           \n",
    "    for i in range(len(rows)):\n",
    "        x=rows[i]\n",
    "        y=cols[i]\n",
    "        for k in range(128):\n",
    "            value=x*coses[k]+y*sins[k]\n",
    "            j = np.argmin(np.abs(radius - value))      #对每个黑色像素点在每个theta上循环计算半径值，并归到radius轴上离它最近的位置\n",
    "            accumulator[j,k]+=1                        #这一部分循环像素点(500*500图像可能有20万次上下）对资源的消耗最大\n",
    "           \n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "    accumulator_max=np.zeros(16*7) #通过将(140,128)维的累计器分成(16,7)组，并通过在每组内取最大值的方式降维到(16,7)\n",
    "    for i in range(16):\n",
    "        if np.sum(bins == i+1)==0:\n",
    "                accumulator_max[i*7:(i+1)*7]=0 #如果弹性网络划分出来了一个空集，那么将这个区域的累计器直接置零；避免索引出一个空集，\n",
    "                continue                              #然后对空集无法取np.max，从而报错\n",
    "        for j in range(7):\n",
    "                max_value=np.max(accumulator[bins == i + 1,theta_intervals[j]:theta_intervals[j+1]])\n",
    "                accumulator_max[i*7+j]=max_value  #注意bins的划分包括(负无穷，最小划分点)和(最大划分点，正无穷)，因此0\n",
    "                                                   #并不代表最小划分点右侧第一个区间，1才是，所以bin==i+1\n",
    "    return accumulator_max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784f18e",
   "metadata": {},
   "source": [
    "# character-sift-特征提取6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef5fa9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_gradients(image):\n",
    "    # 计算 Sobel 梯度\n",
    "    grad_x = sobel(image, axis=0, mode='constant')\n",
    "    grad_y = sobel(image, axis=1, mode='constant')\n",
    "    \n",
    "    # 初始化特征图\n",
    "    feature_map = np.zeros((image.shape[0], image.shape[1], 8))\n",
    "    \n",
    "    # 梯度向量的集合\n",
    "    grad_vectors = np.stack((grad_x, grad_y), axis=-1)\n",
    "    \n",
    "    # 归一化梯度向量\n",
    "    norms = np.linalg.norm(grad_vectors, axis=2, keepdims=True)\n",
    "    norms[norms == 0] = 1  # 避免零梯度导致的除零错误\n",
    "    normalized_grad_vectors = grad_vectors / norms\n",
    "    \n",
    "    # 定义指定角度的8个单位向量\n",
    "    angles = np.deg2rad([0, 45, 90, 135, 180, 225, 270, 315])\n",
    "    unit_vectors = np.array([[np.cos(angle), np.sin(angle)] for angle in angles])\n",
    "\n",
    "    # 计算余弦相似度\n",
    "    cos_similarity = np.tensordot(normalized_grad_vectors, unit_vectors, axes=([2], [1]))\n",
    "    \n",
    "    # 为每个梯度向量找到最匹配的两个单位向量\n",
    "    best_match_indices = np.argsort(-cos_similarity, axis=2)[:, :, :2]\n",
    "    \n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            indices = best_match_indices[i, j]\n",
    "            nearest_vectors = unit_vectors[indices]\n",
    "            grad_vector = grad_vectors[i, j]\n",
    "\n",
    "            if np.all(grad_vector == 0):\n",
    "                continue\n",
    "\n",
    "            # 计算两个最接近向量的系数\n",
    "            coefficients = np.linalg.solve(nearest_vectors.T, grad_vector)\n",
    "            feature_map[i, j, indices] = coefficients\n",
    "    \n",
    "    return feature_map #500*500*8\n",
    "\n",
    "def cutline(image, t=6):\n",
    "    allPoint = np.sum(image)\n",
    "    if allPoint == 0:\n",
    "        return np.zeros(t**2)\n",
    "    perline = allPoint / t\n",
    "    lie = np.sum(image, axis=0)\n",
    "    hang = np.sum(image, axis=1)\n",
    "\n",
    "    for i in range(1, len(lie)):\n",
    "        lie[i] = lie[i-1] + lie[i]\n",
    "    for i in range(1, len(hang)):\n",
    "        hang[i] = hang[i-1] + hang[i]\n",
    "\n",
    "    lieline = np.array([0] * t + [image.shape[1]])\n",
    "    hangline = np.array([0] * t + [image.shape[0]])\n",
    "\n",
    "    for i in range(0, t-1):\n",
    "        lieline[i+1] = np.argmin(abs(lie - perline * (i + 1))) + 1\n",
    "        hangline[i+1] = np.argmin(abs(hang - perline * (i + 1))) + 1\n",
    "\n",
    "    return lieline, hangline\n",
    "\n",
    "\n",
    "def compute_weighted_feature_map(feature_map, binary_image, t=7): #binary_image 500*500二值图像\n",
    "    # 使用 cutline 函数获取 7x7 网格的分割线\n",
    "    lieline, hangline = cutline(binary_image, t=t)\n",
    "\n",
    "    # 为 7x7 网格初始化特征图\n",
    "    grid_feature_map = np.zeros((t, t, 8))\n",
    "    cell_widths = np.diff(lieline)\n",
    "    cell_heights = np.diff(hangline)\n",
    "    \n",
    "    \n",
    "    for i in range(t):\n",
    "        for j in range(t):\n",
    "            \n",
    "            cell_height=cell_heights[i]\n",
    "            cell_width=cell_widths[j]\n",
    "            \n",
    "            Y=np.arange(hangline[i],hangline[i+1])\n",
    "            X=np.arange(lieline[j],lieline[j+1])\n",
    "            \n",
    "            center_y = (hangline[i] + hangline[i + 1]) // 2\n",
    "            center_x = (lieline[j] + lieline[j + 1]) // 2\n",
    "            \n",
    "            W_X=0.5+(0.5*cell_width-np.abs(X-center_x))/cell_width\n",
    "            W_X=W_X[np.newaxis,:,np.newaxis]\n",
    "            W_X_adj=1-W_X\n",
    "            W_Y=0.5+(0.5*cell_height-np.abs(Y-center_y))/cell_height\n",
    "            W_Y=W_Y[:,np.newaxis,np.newaxis]\n",
    "            W_Y_adj=1-W_Y\n",
    "            \n",
    "            region1=feature_map[hangline[i]:center_y,lieline[j]:center_x]\n",
    "            region2=feature_map[hangline[i]:center_y,center_x:lieline[j+1]]\n",
    "            region3=feature_map[center_y:hangline[i+1],lieline[j]:center_x]\n",
    "            region4=feature_map[center_y:hangline[i+1],center_x:lieline[j+1]]\n",
    "            \n",
    "            \n",
    "            grid_feature_map[i,j] += np.sum(region1*W_Y[0:center_y-hangline[i]]*W_X\\\n",
    "                                                  [:,:center_x-lieline[j]],axis=(0,1))\n",
    "            \n",
    "            grid_feature_map[i,j] += np.sum(region2*W_Y[0:center_y-hangline[i]]*W_X\\\n",
    "                                                  [:,center_x-lieline[j]:],axis=(0,1))\n",
    "            \n",
    "            grid_feature_map[i,j] += np.sum(region3*W_Y[center_y-hangline[i]:]*W_X\\\n",
    "                                                  [:,:center_x-lieline[j]],axis=(0,1))\n",
    "            \n",
    "            grid_feature_map[i,j] += np.sum(region4*W_Y[center_y-hangline[i]:]*W_X\\\n",
    "                                                  [:,center_x-lieline[j]:],axis=(0,1))\n",
    "            \n",
    "            \n",
    "            \n",
    "            if j>0:\n",
    "                grid_feature_map[i,j-1] += np.sum(region1*W_Y[0:center_y-hangline[i]]*W_X_adj\\\n",
    "                                                  [:,:center_x-lieline[j]],axis=(0,1))\n",
    "                grid_feature_map[i,j-1]+= np.sum(region3*W_Y[center_y-hangline[i]:]*W_X_adj\\\n",
    "                                                  [:,:center_x-lieline[j]],axis=(0,1))\n",
    "            \n",
    "            if i>0:\n",
    "                grid_feature_map[i-1,j] += np.sum(region1*W_Y_adj[0:center_y-hangline[i]]*W_X\\\n",
    "                                                  [:,:center_x-lieline[j]],axis=(0,1))\n",
    "                \n",
    "                grid_feature_map[i-1,j] += np.sum(region2*W_Y_adj[0:center_y-hangline[i]]*W_X\\\n",
    "                                                  [:,center_x-lieline[j]:],axis=(0,1))\n",
    "            \n",
    "            if j<t-1:\n",
    "                grid_feature_map[i,j+1] += np.sum(region2*W_Y[0:center_y-hangline[i]]*W_X_adj\\\n",
    "                                                  [:,center_x-lieline[j]:],axis=(0,1))\n",
    "                \n",
    "                grid_feature_map[i,j+1]+= np.sum(region4*W_Y[center_y-hangline[i]:]*W_X_adj\\\n",
    "                                                  [:,center_x-lieline[j]:],axis=(0,1))\n",
    "                \n",
    "                \n",
    "            if i<t-1:\n",
    "                grid_feature_map[i+1,j] += np.sum(region3*W_Y_adj[center_y-hangline[i]:]*W_X\\\n",
    "                                                  [:,:center_x-lieline[j]],axis=(0,1))\n",
    "                \n",
    "                grid_feature_map[i+1,j] += np.sum(region4*W_Y_adj[center_y-hangline[i]:]*W_X\\\n",
    "                                                  [:,center_x-lieline[j]:],axis=(0,1))\n",
    "                \n",
    "            \n",
    "            if i>0 and j>0:\n",
    "                grid_feature_map[i-1,j-1] += np.sum(region1*W_Y_adj[0:center_y-hangline[i]]*W_X_adj\\\n",
    "                                                  [:,:center_x-lieline[j]],axis=(0,1))\n",
    "                \n",
    "            if i>0 and j<t-1:\n",
    "                grid_feature_map[i-1,j+1] += np.sum(region2*W_Y_adj[0:center_y-hangline[i]]*W_X_adj\\\n",
    "                                                  [:,center_x-lieline[j]:],axis=(0,1))\n",
    "                \n",
    "            if i<t-1 and j>0:\n",
    "                grid_feature_map[i+1,j-1] += np.sum(region3*W_Y_adj[center_y-hangline[i]:]*W_X_adj\\\n",
    "                                                  [:,:center_x-lieline[j]],axis=(0,1))\n",
    "                \n",
    "            if i<t-1 and j<t-1:\n",
    "                grid_feature_map[i+1,j+1] += np.sum(region4*W_Y_adj[center_y-hangline[i]:]*W_X_adj\\\n",
    "                                                  [:,center_x-lieline[j]:],axis=(0,1))\n",
    "                \n",
    "                \n",
    "    norms = np.linalg.norm(grid_feature_map, axis=2, keepdims=True)\n",
    "    # 使用L2范数来进行归一化，避免除以0\n",
    "    grid_feature_map = grid_feature_map / np.where(norms == 0, 1, norms)\n",
    "    grid_feature_map = grid_feature_map.flatten()\n",
    "    if np.isnan(grid_feature_map).any() or np.isinf(grid_feature_map).any():\n",
    "        print(\"数组中包含 NaN 或无穷大值！\")\n",
    "    grid_feature_map[grid_feature_map < 0] = 0  # 确保没有负数\n",
    "    grid_feature_map = np.nan_to_num(grid_feature_map)  # 替换 NaN 或无穷值\n",
    "    grid_feature_map = grid_feature_map**(0.4)  # 执行幂次运算\n",
    "    \n",
    "            \n",
    "    return grid_feature_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5b955c",
   "metadata": {},
   "source": [
    "# 80维内外轮廓特征+20维特征词袋embedding-特征提取7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "715fbcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#见https://github.com/caojiaolong/Fu-Character-Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e44a8",
   "metadata": {},
   "source": [
    "# 特征提取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ede9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeature(method,path,save=True,output_path=None):\n",
    "    filenames = [f for f in os.listdir(path) if f.endswith('.png')]\n",
    "    filenames.sort()\n",
    "    all_features = []\n",
    "    times = 0\n",
    "    for filename in tqdm(filenames):\n",
    "        imagePath = os.path.join(path,filename)\n",
    "        image = cv2.imread(imagePath,cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if image is None:\n",
    "            print(filename)\n",
    "            break\n",
    "            \n",
    "        if method == \"hough\": #hough计算过于昂贵，故下采样\n",
    "            image = cv2.resize(image, (140,140), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        _,binary_resized_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "        img = (image == 0).astype(int)\n",
    "        \n",
    "        if method == \"ZBH\":\n",
    "            feature = statistics_strokes_extraction(img)\n",
    "        elif method == \"NWHog\":\n",
    "            feature = extract_feature(img)\n",
    "        elif method == \"Gabor\":\n",
    "            feature = gabor_extraction(img,filters)\n",
    "        elif method == \"STXGabor\":\n",
    "            feature = gabor_ZiBiHua(img)\n",
    "        elif method == \"hough\":\n",
    "            feature=hough_extraction(img)\n",
    "        elif method == \"Character-SIFT\":\n",
    "            sobel_feature_map = sobel_gradients(img)\n",
    "            feature = compute_weighted_feature_map(sobel_feature_map, img, t=7)\n",
    "        else:\n",
    "            print(\"WRONG METHOD!\")\n",
    "            break\n",
    "\n",
    "        all_features.append(feature)\n",
    "        times += 1\n",
    "    print(\"共得到%d个图片的特征\" % times)\n",
    "    features_array=np.array(all_features)\n",
    "    \n",
    "    if save==True:\n",
    "        np.save(output_path, features_array)\n",
    "        \n",
    "    return features_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9777d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makeFeature(method=\"Gabor\",path=r\"D:\\\\data\\\\a\",save=True,output_path=\"D:\\\\data\\\\a\\\\gabor.npy\")\n",
    "#makeFeature(method=\"ZBH\",path=r\"D:\\\\data\\\\a\",save=True,output_path=\"D:\\\\data\\\\a\\\\ZBH.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skimage",
   "language": "python",
   "name": "skimage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
